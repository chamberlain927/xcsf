################
# General XCSF #
################

OMP_NUM_THREADS=8 # number of threads for parallel processing
POP_SIZE=2000 # maximum number of macro-classifiers in the population
MAX_TRIALS=100000 # number of learning trials to perform
POP_INIT=true # whether to fill the initial population with random classifiers
PERF_AVG_TRIALS=1000 # number of trials to average performance output
LOSS_FUNC=0 # Mean Absolute Error loss function (use for mazes and mux)
#LOSS_FUNC=1 # Mean Squared Error
#LOSS_FUNC=2 # Root Mean Squared Error
#LOSS_FUNC=3 # Log loss; for multi-class classification
#LOSS_FUNC=4 # Binary log loss; for binary-class classification
#LOSS_FUNC=5 # One-hot encoding accuracy; for classification

#########################
# Multi-step parameters #
#########################

TELETRANSPORTATION=50 # num steps to reset a multistep problem if goal not found
GAMMA=0.95 # discount factor in calculating the reward for multistep problems
P_EXPLORE=0.9 # probability of exploring vs. exploiting in a multistep trial

######################
# General Classifier #
######################

ALPHA=1.0 # amount to reduce inaccurate classifier's accuracy (1=disabled)
BETA=0.1 # learning rate for updating error, fitness, and set size
DELTA=0.1 # fraction of least fit classifiers to increase deletion vote
NU=5.0 # exponent used in calculating classifier accuracy
THETA_DEL=20 # min experience before fitness used in probability of deletion
INIT_FITNESS=0.01 # initial classifier fitness
INIT_ERROR=0.0 # initial classifier error
ERR_REDUC=1.0 # amount to reduce an offspring's error (1=disabled)
FIT_REDUC=0.1 # amount to reduce an offspring's fitness (1=disabled)
EPS_0=0.01 # classifier target error, under which fitness is set to 1

###############
# Subsumption #
###############

EA_SUBSUMPTION=false # whether to try and subsume offspring classifiers
SET_SUBSUMPTION=false # whether to perform match set subsumption
THETA_SUB=1000 # minimum experience of a classifier to become a subsumer
 
##########################
# Evolutionary Algorithm #
##########################

EA_SELECT_TYPE=0 # roulette wheel parental selection
#EA_SELECT_TYPE=1 # tournament parental selection
EA_SELECT_SIZE=0.4 # fraction of set size for tournament parental selection
THETA_EA=50.0 # average set time between EA invocations
LAMBDA=2 # number of offspring to create each EA invocation
P_CROSSOVER=0.80 # probability of applying crossover
S_MUTATION=0.1 # standard deviation of normal used to mutate a gene
P_MUTATION=0.04 # probability of mutation occuring per gene
F_MUTATION=0.04 # probability of mutating graph/network functions
E_MUTATION=0.04 # stdev. of normal added to rate of gradient descent

# Self-adaptive mutation parameters
SAM_TYPE=0 # log normal adaptation
#SAM_TYPE=1 # ten normally distributed rates
#SAM_NUM=0 # fixed rates of mutation (using the values above)
#SAM_NUM=1 # self-adapts S_MUTATION
#SAM_NUM=2 # self-adapts S_MUTATION and P_MUTATION
#SAM_NUM=3 # self-adapts all of the above and E_MUTATION
SAM_NUM=4 # self-adapts all of the above and F_MUTATION
SAM_MIN=0.01 # minimum value of a log normal self-adaptive mutation rate
 
########################
# Classifier Condition #
########################

MIN_CON=0.0 # minimum input value
MAX_CON=1.0 # maximum input value

# Condition type
#COND_TYPE=-1# always matching dummy condition
COND_TYPE=0 # hyperrectangles
#COND_TYPE=1 # hyperellipsoids
#COND_TYPE=2 # multi-layer perceptron neural networks
#COND_TYPE=3 # GP trees
#COND_TYPE=4 # dynamical GP graphs
#COND_TYPE=11 # both conditions and actions in single dynamical GP graphs
#COND_TYPE=12 # both conditions and actions in single neural networks

COND_ETA=0.0 # gradient descent rate for updating the condition

# Tree-GP
GP_NUM_CONS=100 # number of (shared) constants available for GP trees 
GP_INIT_DEPTH=5 # initial depth of GP trees

# DGP
DGP_NUM_NODES=20 # number of nodes in a DGP graph
RESET_STATES=true # whether to reset DGP initial states each trial
MAX_K=2 # maximum number of connections a DGP node may have
MAX_T=10 # maximum number of cycles to update a DGP graph

# Neural network
COND_EVOLVE_WEIGHTS=true
COND_EVOLVE_NEURONS=true
COND_EVOLVE_FUNCTIONS=false
COND_NUM_HIDDEN_NEURONS=1 # initial number of hidden neurons (random if <= 0)
COND_MAX_HIDDEN_NEURONS=10 # maximum number of neurons if evolved
# Neural Network hidden layer activation function (if not evolved)
COND_HIDDEN_NEURON_ACTIVATION=0 # Logistic
#COND_HIDDEN_NEURON_ACTIVATION=1 # Rectified linear unit
#COND_HIDDEN_NEURON_ACTIVATION=2 # TanH
#COND_HIDDEN_NEURON_ACTIVATION=3 # Identity
#COND_HIDDEN_NEURON_ACTIVATION=4 # Gaussian
#COND_HIDDEN_NEURON_ACTIVATION=5 # Sinusoid
#COND_HIDDEN_NEURON_ACTIVATION=6 # Cosine
#COND_HIDDEN_NEURON_ACTIVATION=7 # Soft plus
#COND_HIDDEN_NEURON_ACTIVATION=8 # Leaky rectified linear unit
#COND_HIDDEN_NEURON_ACTIVATION=9 # Scaled exponential linear unit

#########################
# Classifier Prediction #
#########################

# Prediction type
PRED_TYPE=0 # linear least squares
#PRED_TYPE=1 # quadratic least squares
#PRED_TYPE=2 # linear recursive least squares
#PRED_TYPE=3 # quadratic recursive least squares
#PRED_TYPE=4 # stochastic gradient descent multilayer perceptron neural networks

PRED_ETA=0.10 # gradient descent rate for updating the prediction
PRED_RESET=false # whether to reset offspring predictions instead of copying

# Least squares
PRED_X0=1.0 # prediction weight vector offset value
PRED_RLS_SCALE_FACTOR=1000.0 # initial diagonal values of the RLS gain-matrix
PRED_RLS_LAMBDA=1.0 # forget rate for RLS (small values may be unstable)

# Neural network
PRED_EVOLVE_WEIGHTS=true
PRED_EVOLVE_NEURONS=true
PRED_EVOLVE_FUNCTIONS=false
PRED_EVOLVE_ETA=true
PRED_SGD_WEIGHTS=true
PRED_MOMENTUM=0.9 # momentum for gradient descent update
PRED_NUM_HIDDEN_NEURONS=1 # initial number of hidden neurons (random if <= 0)
PRED_MAX_HIDDEN_NEURONS=10 # maximum number of neurons if evolved
# Neural Network hidden layer activation function (if not evolved)
PRED_HIDDEN_NEURON_ACTIVATION=0 # Logistic
#PRED_HIDDEN_NEURON_ACTIVATION=1 # Rectified linear unit
#PRED_HIDDEN_NEURON_ACTIVATION=2 # TanH
#PRED_HIDDEN_NEURON_ACTIVATION=3 # Identity
#PRED_HIDDEN_NEURON_ACTIVATION=4 # Gaussian
#PRED_HIDDEN_NEURON_ACTIVATION=5 # Sinusoid
#PRED_HIDDEN_NEURON_ACTIVATION=6 # Cosine
#PRED_HIDDEN_NEURON_ACTIVATION=7 # Soft plus
#PRED_HIDDEN_NEURON_ACTIVATION=8 # Leaky rectified linear unit
#PRED_HIDDEN_NEURON_ACTIVATION=9 # Scaled exponential linear unit

#####################
# Classifier Action #
#####################

# Action type
ACT_TYPE=0 # integer
